# E2E Integration Tests - Complete Guide

**Status**: ‚úÖ COMPLETE - 15 comprehensive integration tests

---

## üìã Overview

Automated end-to-end integration tests that validate the entire flow:

1. **Database Setup** - Create fresh test database
2. **Schema Creation** - Run migrations programmatically
3. **Seed Data** - Create test customer, API key, policies
4. **API Calls** - Execute /v1/check requests
5. **Governance Logic** - Validate risk scoring and blocking
6. **Rate Limiting** - Test request limits
7. **Error Handling** - Test authentication and validation
8. **Cleanup** - Drop test database

---

## üìÅ Files Created/Modified

### New Files

#### `backend/tests/test_integration.py` (420 lines)
```python
‚úÖ 15 comprehensive E2E tests:
   1. Health endpoint
   2. Invalid API key rejection
   3. Missing auth header rejection
   4. Allowed operation (no risk)
   5. Blocked personal data
   6. Blocked external model
   7. Blocked high risk (combined)
   8. Forbidden field 'prompt'
   9. Forbidden field 'content'
   10. Multiple requests same key
   11. Rate limiting enforcement
   12. Response structure validation
   13. Different model values
   14. Edge case: empty metadata
   15. Edge case: null metadata

‚úÖ Features:
   - Async database setup (AsyncEngine)
   - Automatic test database creation/cleanup
   - Seed data generation (customer, API key, policies)
   - httpx.AsyncClient for testing
   - Comprehensive assertions
```

#### `docker-compose.test.yml`
```yaml
‚úÖ Dedicated test PostgreSQL service:
   - Port: 5433 (different from main 5432)
   - Database: test_ai_governance
   - Healthcheck included
   - Volume: test_db_data
```

### Modified Files

#### `.github/workflows/ci.yml`
```yaml
‚úÖ Updated CI workflow:
   - Separate unit tests (test_health.py)
   - Create test database (test_ai_governance)
   - Run E2E integration tests (test_integration.py)
   - Proper environment variables:
     * DATABASE_URL (main DB)
     * TEST_DATABASE_URL (test DB)
```

---

## üß™ Test Coverage

### Authentication Tests (3)
- ‚úÖ Test invalid API key returns 401
- ‚úÖ Test missing auth header returns 401
- ‚úÖ Test valid key authenticates

### Governance Logic Tests (5)
- ‚úÖ Allowed operation (no risk flags)
- ‚úÖ Blocked personal data (risk = 70)
- ‚úÖ Blocked external model (risk = 50)
- ‚úÖ Blocked high risk (risk = 120, both flags)
- ‚úÖ Response structure validation

### Security Tests (2)
- ‚úÖ Forbidden field 'prompt' rejected
- ‚úÖ Forbidden field 'content' rejected

### Rate Limiting Tests (1)
- ‚úÖ 100+ requests in window validated

### Edge Cases (3)
- ‚úÖ Multiple requests with same key
- ‚úÖ Different model values accepted
- ‚úÖ Empty/null metadata handled

### Infrastructure (1)
- ‚úÖ Health endpoint works

---

## üöÄ Running Tests Locally

### Option 1: Using Docker Compose (Recommended)

```bash
# Start test database
docker-compose -f docker-compose.test.yml up -d

# Wait for database to be ready
sleep 5

# Install dependencies
cd backend
pip install -r requirements.txt

# Run integration tests
export TEST_DATABASE_URL="postgresql+asyncpg://postgres:postgres@localhost:5433/test_ai_governance"
pytest -v tests/test_integration.py

# Cleanup
docker-compose -f docker-compose.test.yml down
```

### Option 2: Using Local PostgreSQL

```bash
# Ensure PostgreSQL is running
# Create test database
psql -U postgres -c "CREATE DATABASE test_ai_governance;"

# Run tests
cd backend
export TEST_DATABASE_URL="postgresql+asyncpg://postgres:postgres@localhost:5432/test_ai_governance"
pytest -v tests/test_integration.py
```

### Option 3: Run All Tests (Unit + Integration)

```bash
# In backend directory
pytest -v tests/
```

### Option 4: Run Specific Test

```bash
# Run single test
pytest -v tests/test_integration.py::TestE2EIntegration::test_allowed_operation

# Run tests matching pattern
pytest -v tests/test_integration.py -k "test_blocked"
```

---

## üìä Test Results Example

### Successful Run
```
test_integration.py::TestE2EIntegration::test_health_endpoint PASSED
test_integration.py::TestE2EIntegration::test_auth_invalid_key PASSED
test_integration.py::TestE2EIntegration::test_auth_missing_header PASSED
test_integration.py::TestE2EIntegration::test_allowed_operation PASSED
test_integration.py::TestE2EIntegration::test_blocked_personal_data PASSED
test_integration.py::TestE2EIntegration::test_blocked_external_model PASSED
test_integration.py::TestE2EIntegration::test_blocked_high_risk PASSED
test_integration.py::TestE2EIntegration::test_forbidden_field_prompt PASSED
test_integration.py::TestE2EIntegration::test_forbidden_field_content PASSED
test_integration.py::TestE2EIntegration::test_multiple_requests_same_key PASSED
test_integration.py::TestE2EIntegration::test_rate_limiting PASSED
test_integration.py::TestE2EIntegration::test_response_structure PASSED
test_integration.py::TestE2EIntegration::test_different_models PASSED
test_integration.py::TestE2EIntegration::test_edge_case_empty_metadata PASSED
test_integration.py::TestE2EIntegration::test_edge_case_null_metadata PASSED

=============== 15 passed in 8.23s ===============
```

---

## üîß How It Works

### 1. Database Setup (Fixtures)

```python
@pytest.fixture(scope="session")
async def test_engine():
    """Create test database engine"""
    engine = create_async_engine(TEST_DATABASE_URL)
    
    # Drop any existing tables
    async with engine.begin() as conn:
        await conn.run_sync(Base.metadata.drop_all)
        await conn.run_sync(Base.metadata.create_all)
    
    yield engine
    
    # Cleanup after all tests
    async with engine.begin() as conn:
        await conn.run_sync(Base.metadata.drop_all)
```

### 2. Seed Data Generation

```python
@pytest.fixture
async def seed_data(db_session):
    """Create test customer, API key, and policies"""
    
    # 1. Create customer
    customer = Customer(...)
    
    # 2. Generate API key
    raw_key = f"test_key_{uuid.uuid4().hex[:24]}"
    key_hash = bcrypt.hashpw(raw_key.encode(), bcrypt.gensalt())
    api_key = APIKey(api_key_hash=key_hash, ...)
    
    # 3. Create policies
    policy_allow = Policy(key="default_allow", ...)
    policy_personal = Policy(key="personal_data_protection", ...)
    policy_external = Policy(key="external_model_restriction", ...)
    
    # 4. Assign policies to customer
    CustomerPolicy(customer_id=..., policy_id=..., ...)
    
    await db_session.commit()
    return {raw_key, policies, customer}
```

### 3. Test Execution

```python
@pytest.mark.asyncio
async def test_allowed_operation(client, seed_data):
    """Test that valid request is allowed"""
    
    # Get credentials from seed_data
    raw_key = seed_data["raw_key"]
    
    # Make API request
    response = await client.post(
        "/v1/check",
        json={
            "model": "gpt-4",
            "operation": "chat_completion",
            "metadata": {"temperature": 0.7}
        },
        headers={"Authorization": f"Bearer {raw_key}"}
    )
    
    # Assert response
    assert response.status_code == 200
    data = response.json()
    assert data["allowed"] is True
    assert data["risk_score"] == 0
```

### 4. Cleanup

```python
@pytest.fixture(scope="session")
async def test_engine():
    yield engine  # Tests run here
    
    # After all tests complete:
    async with engine.begin() as conn:
        await conn.run_sync(Base.metadata.drop_all)  # ‚Üê Cleanup
    await engine.dispose()
```

---

## üîê CI/CD Integration

### GitHub Actions Workflow

```yaml
name: CI
on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    services:
      postgres:  # Main DB
        image: postgres:15
        env:
          POSTGRES_DB: ai_governance
    
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v4
      - run: cd backend && pip install -r requirements.txt
      
      # Unit tests against main DB
      - run: pytest -v tests/test_health.py
      
      # Create test DB
      - run: psql -c "CREATE DATABASE test_ai_governance;"
      
      # E2E integration tests
      - run: |
          export TEST_DATABASE_URL=postgresql+asyncpg://...
          pytest -v tests/test_integration.py
```

### What Happens on Push/PR

1. ‚úÖ GitHub spins up PostgreSQL container (5432)
2. ‚úÖ Python environment set up
3. ‚úÖ Dependencies installed
4. ‚úÖ Run unit tests (fast, <2s)
5. ‚úÖ Create test database
6. ‚úÖ Run E2E integration tests (full flow, ~10s)
7. ‚úÖ All tests must pass before merge

---

## üö® Troubleshooting

### "Connection refused" Error

**Problem**: Test database not running

**Solution**:
```bash
# Option 1: Start with Docker
docker-compose -f docker-compose.test.yml up -d

# Option 2: Use existing PostgreSQL
createdb test_ai_governance
```

### "No module named 'main'" Error

**Problem**: Python path not set correctly

**Solution**:
```bash
# Ensure you're in backend directory
cd backend

# Run pytest from backend
pytest -v tests/test_integration.py
```

### "Database already exists" Error

**Problem**: Test database still from previous run

**Solution**:
```bash
# Option 1: Drop and recreate
dropdb test_ai_governance
psql -c "CREATE DATABASE test_ai_governance;"

# Option 2: Use Docker volume cleanup
docker-compose -f docker-compose.test.yml down -v
```

### "Timeout waiting for database" Error

**Problem**: PostgreSQL taking too long to start

**Solution**:
```bash
# Add delay before running tests
sleep 10

# Or wait for healthcheck
docker-compose -f docker-compose.test.yml up -d
docker-compose -f docker-compose.test.yml exec postgres pg_isready
```

---

## üìà Performance

### Local Execution
- Test setup: ~1s
- Seed data: ~500ms
- 15 tests: ~6-8s
- Cleanup: ~200ms
- **Total**: ~8-10 seconds

### CI/CD Execution
- Database creation: ~3s
- Test setup: ~1s
- 15 tests: ~8-10s
- **Total**: ~15-20 seconds

### Optimization Tips
- Use `pytest -x` to stop on first failure
- Use `pytest -k pattern` to run subset
- Use `pytest --tb=short` for concise output
- Combine with `-n auto` (pytest-xdist) for parallel runs

---

## üéØ Test Scenarios Covered

| Scenario | Test | Coverage |
|----------|------|----------|
| **Health Check** | test_health_endpoint | API available |
| **Authentication** | test_auth_* | Key validation |
| **Allowed Ops** | test_allowed_operation | Normal flow works |
| **Risk Blocking** | test_blocked_* | Governance enforced |
| **Security** | test_forbidden_field_* | Content protection |
| **Rate Limit** | test_rate_limiting | Request throttling |
| **Data Validation** | test_response_structure | Schema compliance |
| **Edge Cases** | test_edge_case_* | Robustness |
| **Volume** | test_multiple_requests | Stability |
| **Variety** | test_different_models | Flexibility |

---

## üîó Related Files

- `backend/tests/test_integration.py` - Full test suite
- `backend/tests/test_health.py` - Unit tests
- `docker-compose.test.yml` - Test database
- `.github/workflows/ci.yml` - CI/CD pipeline
- `backend/pytest.ini` - Test configuration
- `backend/requirements.txt` - Dependencies

---

## üìä Command Reference

```bash
# Run all tests
pytest -v tests/

# Run only integration tests
pytest -v tests/test_integration.py

# Run only unit tests
pytest -v tests/test_health.py

# Run specific test
pytest -v tests/test_integration.py::TestE2EIntegration::test_allowed_operation

# Run tests matching pattern
pytest -v tests/ -k "allowed"

# Show detailed output on failure
pytest -vv --tb=long tests/test_integration.py

# Stop on first failure
pytest -x tests/test_integration.py

# Generate coverage report
pytest --cov=. tests/

# Run in parallel (requires pytest-xdist)
pytest -n auto tests/
```

---

## ‚úÖ Validation Checklist

Before deployment:
- [ ] All 15 E2E tests passing locally
- [ ] All 2 unit tests passing
- [ ] CI/CD tests passing on GitHub
- [ ] No flaky tests (run multiple times)
- [ ] Performance acceptable (<15s CI)
- [ ] Test database cleanup working

---

## üìû Support

**Need help?**
1. Check `.github/workflows/ci.yml` for CI setup
2. See `docker-compose.test.yml` for database config
3. Review `backend/tests/test_integration.py` for examples
4. Check `backend/pytest.ini` for pytest settings

---

**Created**: November 16, 2025  
**Status**: ‚úÖ Production Ready  
**Version**: 1.0
